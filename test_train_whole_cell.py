#%%
import torch
from scipy.spatial import KDTree
from whole_cell import WholeCell
from random_function import random_system, print_system, f_pow
from matplotlib import pyplot as plt
import scipy
from pyVIA.core import *
from matplotlib import pyplot as plt


#%%
# Generate a random system of equations
num_nodes = 2
max_terms = 3
library = [f_pow(1), f_pow(0), torch.sin, torch.cos, f_pow(2)]
system, terms = random_system(num_nodes, library, krange=1/10, max_terms=3, self_deg=True)
print_system(terms)

#%%
# Run the system of equations from nstarts random initial conditions until convergence or maxsteps
nstarts = 15
starts = torch.randn(nstarts, num_nodes)*2
h = 0.1
maxsteps = 15000
eps = 1e-6
runs = []
for i, start in enumerate(starts):
    print(i)
    run = torch.zeros(maxsteps, num_nodes)
    x = start
    for j in range(maxsteps):
        # Euler step
        u = system(x)
        # If the magnitude of the maximum update is less than eps, we have converged
        du = torch.max(torch.abs(h*u))
        if du < eps:
            print('converged', flush=True)
            print(x)
            runs.append(run[:j])
            break
        x = x + h*u
        run[j] = x

#%%
# Downsample the points generated by the simulations of the system
data = torch.cat(runs)
sample_factor = 10
# Take every Nth point from each run
sampled = torch.zeros(0, num_nodes)
for run in runs:
    sampled = torch.cat([sampled, run[::sample_factor]])
# Add noise to the sampled points
# TODO maybe add noise during the simulation?
noise_factor = 0.1
sampled = sampled + torch.randn(sampled.shape)*noise_factor
plt.scatter(sampled[:,0], sampled[:,1], s=1)
for i in range(nstarts):
    plt.scatter(runs[i][:,0], runs[i][:,1], s=1)


#%% 
# Plot the sampled points

#%% 
# Old code that I used to compute pseudo-time trajectories using scanpy
# from scanpy.tl import paga, leiden, dpt, diffmap
# from scanpy.pp import neighbors
from scanpy import AnnData
import scanpy as sc
import numpy as np
adata = AnnData(sampled.detach().numpy())
# print('Computing neighbors')
# n_neighbors = 100
# neighbors(adata, n_neighbors=n_neighbors)
# print('Computing leiden clusters')
# leiden(adata)
# print('Computing PAGA')
# paga(adata)
print('Setting root')
end = runs[0][-1].detach().numpy()
root = np.flatnonzero(np.abs(sampled - end)<1e-4)[0]
# print('Computing diffmap')
# diffmap(adata)
# print('Computing diffusion pseudotime')
# dpt(adata)

#%%
# Old code that I used to construct a flow field from the diffusion pseudo-times assigned to each point
# This procedure still sometimes give weird values for the inferred flow field
# Get the nearest neighbors that have a larger pseudo-time for each point
# transition_sigma = 1e-1
# transition_points = []
# for i in range(len(sampled)):
#     # Sparse matrix row for the current point
#     row=adata.obsp['distances'][i]
#     closest_in_row = np.argmin(row[row > 0])
#     # indexes of non-zero entries in the sparse matrix row
#     nonzeros = row.nonzero()[1]
#     closest_idx = nonzeros[closest_in_row]
#     closest = sampled[closest_idx]
#     transition_points.append(closest)

# min_transition_points = torch.vstack(transition_points)
# # mean_transition_points = torch.vstack([torch.mean(sampled[points], dim=0) for points in transition_points])


#%%
# Use pyVIA to compute the flow field
ncomps = 30
knn = 75
random_seed = 42

via = VIA(adata.X, jac_std_global=0.15, dist_std_local=1,
             knn=knn, cluster_graph_pruning_std=1, too_big_factor=0.3, 
             root_user=None, preserve_disconnected=True,
             random_seed=random_seed)
via.run_VIA()

#%% 
# Plot the results from the VIA graph
via_streamplot(via, sampled.detach().numpy(), scatter_size=1, bg_color='white', )


#%%
# Get the transition matrix from the VIA graph
X = via.data
T = via.single_cell_transition_matrix
V = np.zeros(X.shape)
n_obs = X.shape[0]
#the change in embedding distance when moving from cell i to its neighbors is given by dx
for i in range(n_obs):
    indices = T[i].indices
    dX = X[indices] - X[i, None]  # shape (n_neighbors, 2)
    dX /= l2_norm(dX)[:, None]

    # dX /= np.sqrt(dX.multiply(dX).sum(axis=1).A1)[:, None]
    dX[np.isnan(dX)] = 0  # zero diff in a steady-state
    #neighbor edge weights are used to weight the overall dX or velocity from cell i.
    probs =  T[i].data
    #if probs.size ==0: print('velocity embedding probs=0 length', probs, i, self.true_label[i])
    V[i] = probs.dot(dX) - probs.mean() * dX.sum(0)

# bad hack that I have to do because VIA doesn't like working with low dimensional data
# Setting nan values to zero. Nan values occur when a point has no neighbors
V[np.isnan(V).sum(axis=1) > 0] = 0

#%%
def plot_arrows(points, V, pV=None, sample_factor=10, save_file=None):
    # Plot the vectors from the sampled points to the transition points
    # Increase the size of the plot to see the vectors
    plt.figure(figsize=(15,15))
    plt.scatter(points[:,0], points[:,1], s=3)
    # black = true vectors
    # Green = predicted vectors
    for i in range(0, len(V), sample_factor):
        plt.arrow(points[i,0], points[i,1], V[i,0], V[i,1], color='black', alpha=1, width=0.015)
        if pV is not None:
            plt.arrow(points[i,0], points[i,1], pV[i,0], pV[i,1], color='g', alpha=1, width=0.015)

    if save_file is not None:
        plt.savefig(save_file)

plot_arrows(sampled.detach().cpu().numpy(), V, sample_factor=10)
plt.scatter(sampled[:,0], sampled[:,1], s=3)#, c=adata.obs['dpt_pseudotime'])


#%%
def plot_traces(model, trace_starts, i, n_traces=50):
    # Generate some sample traces
    traces = model.trajectory(state=trace_starts, tspan=torch.linspace(0, 100, 500))
    trace_plot = traces.cpu().detach().numpy()
    # Create a new figure
    fig, ax = plt.subplots()
    # Plot the data with partial transparency so that we can highlight the traces
    ax.scatter(data[:,0], data[:,1], s=.25, alpha=0.1)
    print(trace_plot.shape)
    for trace in range(n_traces):
        print(trace, n_traces)
        # Plot the traces
        ax.scatter(trace_plot[:,trace,0], trace_plot[:,trace,1], s=1)
    # Save the plot to a file indicating the epoch
    plt.savefig(f'figures/test/traces_{i}.png')

#%%
device = 'cuda:0'
model = WholeCell(input_dim=num_nodes, 
                  output_dim=num_nodes, 
                  hidden_dim=12, num_layers=3).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = torch.nn.MSELoss(reduction='mean')
sampled = sampled.to(device)
V = torch.tensor(V).to(torch.float32).to(device)
#%%
mse = torch.nn.MSELoss(reduction='mean')

n_epoch = 10000
n_points = 1000
n_traces = 50
trace_starts = sampled[torch.randint(0, sampled.shape[0], (n_traces,))]
n_samples = 10

#%%
for i in range(n_epoch):
    optimizer.zero_grad()
    # Run the model from N randomly selected data points
    # Random sampling
    # idxs = torch.randint(0, sampled.shape[0], (n_points,))
    
    # TODO Note we're sampling all the points here, but we should be sampling a subset
    # Data is small enough that we can take the full set
    idxs = torch.arange(sampled.shape[0])
    starts = sampled[idxs]
    # TODO do we need to change the tspan?
    # tspan is a single step from zero to one
    _, fx = model(starts, tspan=torch.linspace(0,1,2))
    velocity = V[idxs]
    # Compute the loss between the predicted and true velocity vectors
    loss = mse(fx[-1], velocity)
    loss.backward()
    optimizer.step()
    print(i,' '.join([f'{x.item():.9f}' for x in 
          [loss]]), flush=True)
    if i % 100 == 0:
        plot_arrows(sampled.detach().cpu(), 
                    fx[-1].detach().cpu(),
                    velocity.detach().cpu(),
                    sample_factor=10,
                    save_file=f'figures/test/vector_field_{i}.png')
    if i%1000 == 0:
        plot_traces(model, trace_starts, i, n_traces=n_traces)
        torch.save(model.state_dict(), 'simple_model.torch')

    plt.close()
# %%
